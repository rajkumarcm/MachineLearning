{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M7-0S4xezlEf",
    "pycharm": {
     "name": "#%% md\n"
    },
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Overview\" data-toc-modified-id=\"Overview-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Overview</a></span></li><li><span><a href=\"#Notebook-Configuration\" data-toc-modified-id=\"Notebook-Configuration-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Notebook Configuration</a></span><ul class=\"toc-item\"><li><span><a href=\"#Google-drive\" data-toc-modified-id=\"Google-drive-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Google drive</a></span></li><li><span><a href=\"#Warning\" data-toc-modified-id=\"Warning-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Warning</a></span></li><li><span><a href=\"#Matplotlib\" data-toc-modified-id=\"Matplotlib-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Matplotlib</a></span></li><li><span><a href=\"#TensorFlow\" data-toc-modified-id=\"TensorFlow-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>TensorFlow</a></span></li><li><span><a href=\"#Random-seed\" data-toc-modified-id=\"Random-seed-2.5\"><span class=\"toc-item-num\">2.5&nbsp;&nbsp;</span>Random seed</a></span></li></ul></li><li><span><a href=\"#Data-Preprocessing\" data-toc-modified-id=\"Data-Preprocessing-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Data Preprocessing</a></span><ul class=\"toc-item\"><li><span><a href=\"#Loading-the-data\" data-toc-modified-id=\"Loading-the-data-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Loading the data</a></span></li><li><span><a href=\"#Splitting-the-data\" data-toc-modified-id=\"Splitting-the-data-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Splitting the data</a></span></li><li><span><a href=\"#Handling-uncommon-features\" data-toc-modified-id=\"Handling-uncommon-features-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Handling uncommon features</a></span><ul class=\"toc-item\"><li><span><a href=\"#Identifying-uncommon-features\" data-toc-modified-id=\"Identifying-uncommon-features-3.3.1\"><span class=\"toc-item-num\">3.3.1&nbsp;&nbsp;</span>Identifying uncommon features</a></span></li><li><span><a href=\"#Removing-uncommon-features\" data-toc-modified-id=\"Removing-uncommon-features-3.3.2\"><span class=\"toc-item-num\">3.3.2&nbsp;&nbsp;</span>Removing uncommon features</a></span></li></ul></li><li><span><a href=\"#Handling-identifiers\" data-toc-modified-id=\"Handling-identifiers-3.4\"><span class=\"toc-item-num\">3.4&nbsp;&nbsp;</span>Handling identifiers</a></span><ul class=\"toc-item\"><li><span><a href=\"#Combining-the-training,-validation-and-test-data\" data-toc-modified-id=\"Combining-the-training,-validation-and-test-data-3.4.1\"><span class=\"toc-item-num\">3.4.1&nbsp;&nbsp;</span>Combining the training, validation and test data</a></span></li><li><span><a href=\"#Identifying-identifiers\" data-toc-modified-id=\"Identifying-identifiers-3.4.2\"><span class=\"toc-item-num\">3.4.2&nbsp;&nbsp;</span>Identifying identifiers</a></span></li><li><span><a href=\"#Removing-identifiers\" data-toc-modified-id=\"Removing-identifiers-3.4.3\"><span class=\"toc-item-num\">3.4.3&nbsp;&nbsp;</span>Removing identifiers</a></span></li></ul></li><li><span><a href=\"#Handling-date-time-variables\" data-toc-modified-id=\"Handling-date-time-variables-3.5\"><span class=\"toc-item-num\">3.5&nbsp;&nbsp;</span>Handling date time variables</a></span><ul class=\"toc-item\"><li><span><a href=\"#Transforming-date-time-variables\" data-toc-modified-id=\"Transforming-date-time-variables-3.5.1\"><span class=\"toc-item-num\">3.5.1&nbsp;&nbsp;</span>Transforming date time variables</a></span></li></ul></li><li><span><a href=\"#Handling-missing-data\" data-toc-modified-id=\"Handling-missing-data-3.6\"><span class=\"toc-item-num\">3.6&nbsp;&nbsp;</span>Handling missing data</a></span><ul class=\"toc-item\"><li><span><a href=\"#Combining-the-training,-validation-and-test-data\" data-toc-modified-id=\"Combining-the-training,-validation-and-test-data-3.6.1\"><span class=\"toc-item-num\">3.6.1&nbsp;&nbsp;</span>Combining the training, validation and test data</a></span></li><li><span><a href=\"#Identifying-missing-values\" data-toc-modified-id=\"Identifying-missing-values-3.6.2\"><span class=\"toc-item-num\">3.6.2&nbsp;&nbsp;</span>Identifying missing values</a></span></li><li><span><a href=\"#Separating-the-training,-validation-and-test-data\" data-toc-modified-id=\"Separating-the-training,-validation-and-test-data-3.6.3\"><span class=\"toc-item-num\">3.6.3&nbsp;&nbsp;</span>Separating the training, validation and test data</a></span></li><li><span><a href=\"#Imputing-missing-values\" data-toc-modified-id=\"Imputing-missing-values-3.6.4\"><span class=\"toc-item-num\">3.6.4&nbsp;&nbsp;</span>Imputing missing values</a></span></li></ul></li><li><span><a href=\"#Encoding-the-data\" data-toc-modified-id=\"Encoding-the-data-3.7\"><span class=\"toc-item-num\">3.7&nbsp;&nbsp;</span>Encoding the data</a></span><ul class=\"toc-item\"><li><span><a href=\"#Combining-the-training,-validation-and-test-data\" data-toc-modified-id=\"Combining-the-training,-validation-and-test-data-3.7.1\"><span class=\"toc-item-num\">3.7.1&nbsp;&nbsp;</span>Combining the training, validation and test data</a></span></li><li><span><a href=\"#Identifying-categorical-variables\" data-toc-modified-id=\"Identifying-categorical-variables-3.7.2\"><span class=\"toc-item-num\">3.7.2&nbsp;&nbsp;</span>Identifying categorical variables</a></span></li><li><span><a href=\"#Encoding-categorical-features\" data-toc-modified-id=\"Encoding-categorical-features-3.7.3\"><span class=\"toc-item-num\">3.7.3&nbsp;&nbsp;</span>Encoding categorical features</a></span></li><li><span><a href=\"#Separating-the-training,-validation-and-test-data\" data-toc-modified-id=\"Separating-the-training,-validation-and-test-data-3.7.4\"><span class=\"toc-item-num\">3.7.4&nbsp;&nbsp;</span>Separating the training, validation and test data</a></span></li></ul></li><li><span><a href=\"#Splitting-the-feature-and-target\" data-toc-modified-id=\"Splitting-the-feature-and-target-3.8\"><span class=\"toc-item-num\">3.8&nbsp;&nbsp;</span>Splitting the feature and target</a></span></li><li><span><a href=\"#Scaling-the-data\" data-toc-modified-id=\"Scaling-the-data-3.9\"><span class=\"toc-item-num\">3.9&nbsp;&nbsp;</span>Scaling the data</a></span><ul class=\"toc-item\"><li><span><a href=\"#Standardization\" data-toc-modified-id=\"Standardization-3.9.1\"><span class=\"toc-item-num\">3.9.1&nbsp;&nbsp;</span>Standardization</a></span><ul class=\"toc-item\"><li><span><a href=\"#Standardizing-the-features\" data-toc-modified-id=\"Standardizing-the-features-3.9.1.1\"><span class=\"toc-item-num\">3.9.1.1&nbsp;&nbsp;</span>Standardizing the features</a></span></li><li><span><a href=\"#Standardizing-the-target\" data-toc-modified-id=\"Standardizing-the-target-3.9.1.2\"><span class=\"toc-item-num\">3.9.1.2&nbsp;&nbsp;</span>Standardizing the target</a></span></li></ul></li></ul></li></ul></li><li><span><a href=\"#Hyperparameter-Tuning\" data-toc-modified-id=\"Hyperparameter-Tuning-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Hyperparameter Tuning</a></span><ul class=\"toc-item\"><li><span><a href=\"#Creating-the-dictionary-of-the-models\" data-toc-modified-id=\"Creating-the-dictionary-of-the-models-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Creating the dictionary of the models</a></span></li><li><span><a href=\"#Creating-the-dictionary-of-the-pipelines\" data-toc-modified-id=\"Creating-the-dictionary-of-the-pipelines-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Creating the dictionary of the pipelines</a></span></li><li><span><a href=\"#Getting-the-predefined-split-cross-validator\" data-toc-modified-id=\"Getting-the-predefined-split-cross-validator-4.3\"><span class=\"toc-item-num\">4.3&nbsp;&nbsp;</span>Getting the predefined split cross-validator</a></span></li><li><span><a href=\"#GridSearchCV\" data-toc-modified-id=\"GridSearchCV-4.4\"><span class=\"toc-item-num\">4.4&nbsp;&nbsp;</span>GridSearchCV</a></span><ul class=\"toc-item\"><li><span><a href=\"#Creating-the-dictionary-of-the-parameter-grids\" data-toc-modified-id=\"Creating-the-dictionary-of-the-parameter-grids-4.4.1\"><span class=\"toc-item-num\">4.4.1&nbsp;&nbsp;</span>Creating the dictionary of the parameter grids</a></span><ul class=\"toc-item\"><li><span><a href=\"#The-parameter-grid-for-SGDRegressor\" data-toc-modified-id=\"The-parameter-grid-for-SGDRegressor-4.4.1.1\"><span class=\"toc-item-num\">4.4.1.1&nbsp;&nbsp;</span>The parameter grid for SGDRegressor</a></span></li></ul></li><li><span><a href=\"#Creating-the-directory-for-the-cv-results-produced-by-GridSearchCV\" data-toc-modified-id=\"Creating-the-directory-for-the-cv-results-produced-by-GridSearchCV-4.4.2\"><span class=\"toc-item-num\">4.4.2&nbsp;&nbsp;</span>Creating the directory for the cv results produced by GridSearchCV</a></span></li><li><span><a href=\"#Tuning-the-hyperparameters\" data-toc-modified-id=\"Tuning-the-hyperparameters-4.4.3\"><span class=\"toc-item-num\">4.4.3&nbsp;&nbsp;</span>Tuning the hyperparameters</a></span></li></ul></li></ul></li><li><span><a href=\"#Model-Selection\" data-toc-modified-id=\"Model-Selection-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Model Selection</a></span></li><li><span><a href=\"#Generating-the-Submission-File\" data-toc-modified-id=\"Generating-the-Submission-File-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Generating the Submission File</a></span><ul class=\"toc-item\"><li><span><a href=\"#Creating-the-directory-for-the-submission-file\" data-toc-modified-id=\"Creating-the-directory-for-the-submission-file-6.1\"><span class=\"toc-item-num\">6.1&nbsp;&nbsp;</span>Creating the directory for the submission file</a></span></li><li><span><a href=\"#Generating-the-submission-file\" data-toc-modified-id=\"Generating-the-submission-file-6.2\"><span class=\"toc-item-num\">6.2&nbsp;&nbsp;</span>Generating the submission file</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "42yc1zUrzlEh",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<b>\n",
    "<p>\n",
    "<center>\n",
    "<font size=\"5\">\n",
    "Popular Machine Learning Methods: Idea, Practice and Math\n",
    "</font>\n",
    "</center>\n",
    "</p>\n",
    "\n",
    "<p>\n",
    "<center>\n",
    "<font size=\"4\">\n",
    "Part 2, Chapter 2, Section 2: Training Shallow Models\n",
    "</font>\n",
    "</center>\n",
    "</p>\n",
    "    \n",
    "<p>\n",
    "<center>\n",
    "<font size=\"4\">\n",
    "Case Study\n",
    "</font>\n",
    "</center>\n",
    "</p>\n",
    "\n",
    "<p>\n",
    "<center>\n",
    "<font size=\"3\">\n",
    "Data Science, Columbian College of Arts & Sciences, George Washington University\n",
    "</font>\n",
    "</center>\n",
    "</p>\n",
    "\n",
    "<p>\n",
    "<center>\n",
    "<font size=\"3\">\n",
    "Yuxiao Huang\n",
    "</font>\n",
    "</center>\n",
    "</p>\n",
    "</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rT2SKHw2zlEi",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "asZWLrJKzlEj",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "- This notebook includes the case study for Training Shallow Models (Part 2, Chapter 2, Section 2).\n",
    "- See the accompanied slides in our [github repository](https://github.com/yuxiaohuang/teaching/tree/master/gwu/machine_learning_I/fall_2020/slides/p2_shallow_learning/p2_c2_supervised_learning/p2_c2_s2_training_shallow_models)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WJ-IbZqAgILJ",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Notebook Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H3yB94KtgMHu",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Google drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "executionInfo": {
     "elapsed": 24504,
     "status": "ok",
     "timestamp": 1601086957060,
     "user": {
      "displayName": "Huang Yuxiao",
      "photoUrl": "",
      "userId": "05167076769245149404"
     },
     "user_tz": 240
    },
    "id": "jWmYBTOwgNs-",
    "outputId": "14291049-8e90-4878-8483-616c407b0c0c",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "import sys\n",
    "\n",
    "# Mount Google Drive\n",
    "# drive.mount('/content/drive')\n",
    "\n",
    "# Get the absolute path of the current folder\n",
    "# abspath_curr = 'teaching/gwu/machine_learning_I/homework/homework_1/'\n",
    "\n",
    "# Get the absolute path of the shallow utilities folder\n",
    "# abspath_util_shallow = 'teaching/gwu/machine_learning_I/code/utilities/p2_shallow_learning/'\n",
    "\n",
    "# Get the absolute path of the shallow models folder\n",
    "# abspath_model_shallow = 'teaching/gwu/machine_learning_I/code/models/p2_shallow_learning/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bYZhU1Wqgmqx",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Warning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 24501,
     "status": "ok",
     "timestamp": 1601086957061,
     "user": {
      "displayName": "Huang Yuxiao",
      "photoUrl": "",
      "userId": "05167076769245149404"
     },
     "user_tz": 240
    },
    "id": "MUl4k83e4ANR",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "# Ignore warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6WMODpPfgn2U",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 24499,
     "status": "ok",
     "timestamp": 1601086957061,
     "user": {
      "displayName": "Huang Yuxiao",
      "photoUrl": "",
      "userId": "05167076769245149404"
     },
     "user_tz": 240
    },
    "id": "DBRVH9SB4ANb",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "# Set matplotlib sizes\n",
    "plt.rc('font', size=20)\n",
    "plt.rc('axes', titlesize=20)\n",
    "plt.rc('axes', labelsize=20)\n",
    "plt.rc('xtick', labelsize=20)\n",
    "plt.rc('ytick', labelsize=20)\n",
    "plt.rc('legend', fontsize=20)\n",
    "plt.rc('figure', titlesize=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n-wNDk5nZhhO",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 25951,
     "status": "ok",
     "timestamp": 1601086958514,
     "user": {
      "displayName": "Huang Yuxiao",
      "photoUrl": "",
      "userId": "05167076769245149404"
     },
     "user_tz": 240
    },
    "id": "LjG43tEnZkfE",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# The magic below allows us to use tensorflow version 2.x\n",
    "# %tensorflow_version 2.x\n",
    "# import tensorflow as tf\n",
    "# from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "40FN3UNfO2Z7",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Random seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 25949,
     "status": "ok",
     "timestamp": 1601086958514,
     "user": {
      "displayName": "Huang Yuxiao",
      "photoUrl": "",
      "userId": "05167076769245149404"
     },
     "user_tz": 240
    },
    "id": "uSADk0hJP71d",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# The random seed\n",
    "random_seed = 42\n",
    "\n",
    "# Set random seed in tensorflow\n",
    "# tf.random.set_seed(random_seed)\n",
    "\n",
    "# Set random seed in numpy\n",
    "import numpy as np\n",
    "np.random.seed(random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yAwfz8iYzlFC",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/c/Users/Rajkumar/Desktop/ML coursework experiment'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from os.path import abspath\n",
    "abspath('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "executionInfo": {
     "elapsed": 30321,
     "status": "ok",
     "timestamp": 1601086962910,
     "user": {
      "displayName": "Huang Yuxiao",
      "photoUrl": "",
      "userId": "05167076769245149404"
     },
     "user_tz": 240
    },
    "id": "D-Mwc6MczlFD",
    "outputId": "484b344f-9868-4d89-e262-4e30d014cfcc",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Change working directory to the absolute path of the shallow utilities folder\n",
    "# %cd $abspath_util_shallow\n",
    "\n",
    "# Import the shallow utitilities\n",
    "%run pmlm_utilities_shallow.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oIJsDoJGzlFE",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Loading the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rk5KMdxqzlFE",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "In this code example, we will use the [House Prices (Advanced Regression Techniques) dataset](https://www.kaggle.com/c/house-prices-advanced-regression-techniques)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the raw training data\n",
    "df_raw_train = pd.read_csv('train.csv',\n",
    "                           header=0)\n",
    "# Make a copy of df_raw_train\n",
    "df_train = df_raw_train.copy(deep=True)\n",
    "\n",
    "# Load the raw test data\n",
    "df_raw_test = pd.read_csv('test.csv',\n",
    "                          header=0)\n",
    "# Make a copy of df_raw_test\n",
    "df_test = df_raw_test.copy(deep=True)\n",
    "\n",
    "# Get the name of the target\n",
    "target = 'trip_duration'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Print the dimension of df_train\n",
    "pd.DataFrame([[df_train.shape[0], df_train.shape[1]]], columns=['# rows', '# columns'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Print the dimension of df_test\n",
    "pd.DataFrame([[df_test.shape[0], df_test.shape[1]]], columns=['# rows', '# columns'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Print the first 5 rows of df_train\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Print the first 5 rows of df_test\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Splitting the data\n",
    "The code below shows how to divide the training data into training (80%) and validation (20%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Divide the training data into training (80%) and validation (20%)\n",
    "df_train, df_val = train_test_split(df_train, train_size=0.8, random_state=random_seed)\n",
    "\n",
    "# Reset the index\n",
    "df_train, df_val = df_train.reset_index(drop=True), df_val.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Print the dimension of df_train\n",
    "pd.DataFrame([[df_train.shape[0], df_train.shape[1]]], columns=['# rows', '# columns'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Print the dimension of df_val\n",
    "pd.DataFrame([[df_val.shape[0], df_val.shape[1]]], columns=['# rows', '# columns'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Handling uncommon features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Identifying uncommon features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The code below shows how to find common variables between the training, validation and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Call common_var_checker\n",
    "# See the implementation in pmlm_utilities.ipynb\n",
    "df_common_var = common_var_checker(df_train, df_val, df_test, target)\n",
    "\n",
    "# Print df_common_var\n",
    "df_common_var"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The code below shows how to find features in the training data but not in the validation or test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Get the features in the training data but not in the validation or test data\n",
    "uncommon_feature_train_not_val_test = np.setdiff1d(df_train.columns, df_common_var['common var'])\n",
    "\n",
    "# Print the uncommon features\n",
    "pd.DataFrame(uncommon_feature_train_not_val_test, columns=['uncommon feature'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The code below shows how to find the features in the validation data but not in the training or test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Get the features in the validation data but not in the training or test data\n",
    "uncommon_feature_val_not_train_test = np.setdiff1d(df_val.columns, df_common_var['common var'])\n",
    "\n",
    "# Print the uncommon features\n",
    "pd.DataFrame(uncommon_feature_val_not_train_test, columns=['uncommon feature'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The code below shows how to find the features in the test data but not in the training or validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Get the features in the test data but not in the training or validation data\n",
    "uncommon_feature_test_not_train_val = np.setdiff1d(df_test.columns, df_common_var['common var'])\n",
    "\n",
    "# Print the uncommon features\n",
    "pd.DataFrame(uncommon_feature_test_not_train_val, columns=['uncommon feature'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Removing uncommon features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Remove the uncommon features from the training data\n",
    "df_train = df_train.drop(columns=uncommon_feature_train_not_val_test)\n",
    "\n",
    "# Print the first 5 rows of df_train\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Remove the uncommon features from the validation data\n",
    "df_val = df_val.drop(columns=uncommon_feature_val_not_train_test)\n",
    "\n",
    "# Print the first 5 rows of df_val\n",
    "df_val.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Remove the uncommon features from the test data\n",
    "df_test = df_test.drop(columns=uncommon_feature_test_not_train_val)\n",
    "\n",
    "# Print the first 5 rows of df_test\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Handling identifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Combining the training, validation and test data\n",
    "The code below shows how to combine the training, validation and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Combine df_train, df_val and df_test\n",
    "df = pd.concat([df_train, df_val, df_test], sort=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Identifying identifiers\n",
    "The code below shows how to find identifiers from data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Call id_checker on df\n",
    "# See the implementation in pmlm_utilities.ipynb\n",
    "df_id = id_checker(df)\n",
    "\n",
    "# Print the first 5 rows of df_id\n",
    "df_id.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Removing identifiers\n",
    "The code below shows how to remove identifiers from data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Remove identifiers from df_train\n",
    "df_train.drop(columns=np.intersect1d(df_id.columns, df_train.columns), inplace=True)\n",
    "\n",
    "# Remove identifiers from df_val\n",
    "df_val.drop(columns=np.intersect1d(df_id.columns, df_val.columns), inplace=True)\n",
    "\n",
    "# Remove identifiers from df_test\n",
    "df_test.drop(columns=np.intersect1d(df_id.columns, df_test.columns), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Print the first 5 rows of df_train\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Print the first 5 rows of df_val\n",
    "df_val.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Print the first 5 rows of df_test\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tmp_x = df_train.pickup_datetime.sort_values().unique()\n",
    "import re\n",
    "tmp_y = [re.findall(r'\\d{4}', x)[0]  for x in tmp_x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "np.unique(tmp_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_x = df_train.pickup_datetime.sort_values().unique()\n",
    "import re\n",
    "tmp_y = [re.findall(r'\\d{4}', x)[0]  for x in tmp_x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['2016'], dtype='<U4')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(tmp_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FEWSa3FlVEJ4",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Handling date time variables\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YkvArMXuVEJ4",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Transforming date time variables\n",
    "The code below shows how to transform date time variables into the following 6 datetime types:\n",
    "- year\n",
    "- month\n",
    "- day\n",
    "- hour\n",
    "- minute\n",
    "- second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Personal\n",
    "tmp_df = pd.DataFrame({'y':df_train.YearBuilt})\n",
    "tmp_df2 = datetime_transformer(tmp_df, ['y'])\n",
    "tmp_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Personal\n",
    "tmp_df2.y_year.sort_values().unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Personal\n",
    "df_train.YearBuilt.sort_values().unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 36117,
     "status": "ok",
     "timestamp": 1601086969112,
     "user": {
      "displayName": "Huang Yuxiao",
      "photoUrl": "",
      "userId": "05167076769245149404"
     },
     "user_tz": 240
    },
    "id": "TkLsPcCnOdGi",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Get the date time variables\n",
    "datetime_vars = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "executionInfo": {
     "elapsed": 36094,
     "status": "ok",
     "timestamp": 1601086969112,
     "user": {
      "displayName": "Huang Yuxiao",
      "photoUrl": "",
      "userId": "05167076769245149404"
     },
     "user_tz": 240
    },
    "id": "fVh2HAksVEJ6",
    "outputId": "f189b907-2bad-47f4-91b5-bcf3b44bd290",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Call datetime_transformer on df_train\n",
    "# See the implementation in pmlm_utilities.ipynb\n",
    "df_train = datetime_transformer(df_train, datetime_vars)\n",
    "\n",
    "# Print the first 5 rows of df_train\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "executionInfo": {
     "elapsed": 36071,
     "status": "ok",
     "timestamp": 1601086969112,
     "user": {
      "displayName": "Huang Yuxiao",
      "photoUrl": "",
      "userId": "05167076769245149404"
     },
     "user_tz": 240
    },
    "id": "yE-XP-z8MxNk",
    "outputId": "c5348ca7-6976-4d90-e6af-5fa8bddc1efe",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Call datetime_transformer on df_val\n",
    "# See the implementation in pmlm_utilities.ipynb\n",
    "df_val = datetime_transformer(df_val, datetime_vars)\n",
    "\n",
    "# Print the first 5 rows of df_val\n",
    "df_val.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "executionInfo": {
     "elapsed": 36048,
     "status": "ok",
     "timestamp": 1601086969113,
     "user": {
      "displayName": "Huang Yuxiao",
      "photoUrl": "",
      "userId": "05167076769245149404"
     },
     "user_tz": 240
    },
    "id": "TraRqZFbVEJ8",
    "outputId": "ade7e821-9e33-4271-ffa5-267798faac23",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Call datetime_transformer on df_test\n",
    "# See the implementation in pmlm_utilities.ipynb\n",
    "df_test = datetime_transformer(df_test, datetime_vars)\n",
    "\n",
    "# Print the first 5 rows of df_test\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sreXrgK9zlFi",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Handling missing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2SNvFfHozlFi",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Combining the training, validation and test data\n",
    "The code below shows how to combine the training, validation and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 36047,
     "status": "ok",
     "timestamp": 1601086969113,
     "user": {
      "displayName": "Huang Yuxiao",
      "photoUrl": "",
      "userId": "05167076769245149404"
     },
     "user_tz": 240
    },
    "id": "RRsmSwZRzlFi",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Combine df_train, df_val and df_test\n",
    "df = pd.concat([df_train, df_val, df_test], sort=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wlqQtCbXzlFj",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Identifying missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CXu1rrCPzlFk",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The code below shows how to find variables with NaN, their proportion of NaN and data type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 36023,
     "status": "ok",
     "timestamp": 1601086969113,
     "user": {
      "displayName": "Huang Yuxiao",
      "photoUrl": "",
      "userId": "05167076769245149404"
     },
     "user_tz": 240
    },
    "id": "XlbjyhKxzlFk",
    "outputId": "c31aeb09-adcb-4cf6-9231-d6d36c7414a0",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Call nan_checker on df\n",
    "# See the implementation in pmlm_utilities.ipynb\n",
    "df_nan = nan_checker(df)\n",
    "\n",
    "# Print df_nan\n",
    "df_nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 111
    },
    "executionInfo": {
     "elapsed": 36000,
     "status": "ok",
     "timestamp": 1601086969113,
     "user": {
      "displayName": "Huang Yuxiao",
      "photoUrl": "",
      "userId": "05167076769245149404"
     },
     "user_tz": 240
    },
    "id": "kp8QvrGozlFl",
    "outputId": "75f2e6fc-d402-445f-ba0c-34836db8dcf2",
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Print the unique data type of variables with NaN\n",
    "pd.DataFrame(df_nan['dtype'].unique(), columns=['dtype'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IN-sgksazlFn",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The code below shows how to use data type to select variables with missing values in the combined data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 421
    },
    "executionInfo": {
     "elapsed": 35978,
     "status": "ok",
     "timestamp": 1601086969114,
     "user": {
      "displayName": "Huang Yuxiao",
      "photoUrl": "",
      "userId": "05167076769245149404"
     },
     "user_tz": 240
    },
    "id": "Q-0AhaPlzlFn",
    "outputId": "e9b2b4ec-0ef7-4f28-a92c-0d15153ac30c",
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get the variables with missing values, their proportion of missing values and data type\n",
    "df_miss = df_nan[df_nan['dtype'] == 'float64'].reset_index(drop=True)\n",
    "\n",
    "# Print df_miss\n",
    "df_miss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3sNqs5znzlFo",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Separating the training, validation and test data\n",
    "The code below shows how to separate the training, validation and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 35976,
     "status": "ok",
     "timestamp": 1601086969114,
     "user": {
      "displayName": "Huang Yuxiao",
      "photoUrl": "",
      "userId": "05167076769245149404"
     },
     "user_tz": 240
    },
    "id": "jcK3O9i-zlFo",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Separating the training data\n",
    "df_train = df.iloc[:df_train.shape[0], :]\n",
    "\n",
    "# Separating the validation data\n",
    "df_val = df.iloc[df_train.shape[0]:df_train.shape[0] + df_val.shape[0], :]\n",
    "\n",
    "# Separating the test data\n",
    "df_test = df.iloc[df_train.shape[0] + df_val.shape[0]:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 80
    },
    "executionInfo": {
     "elapsed": 35952,
     "status": "ok",
     "timestamp": 1601086969114,
     "user": {
      "displayName": "Huang Yuxiao",
      "photoUrl": "",
      "userId": "05167076769245149404"
     },
     "user_tz": 240
    },
    "id": "m3rLR944zlFp",
    "outputId": "78cb66ca-68f1-41ad-c418-50033781e852",
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Print the dimension of df_train\n",
    "pd.DataFrame([[df_train.shape[0], df_train.shape[1]]], columns=['# rows', '# columns'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 80
    },
    "executionInfo": {
     "elapsed": 35930,
     "status": "ok",
     "timestamp": 1601086969115,
     "user": {
      "displayName": "Huang Yuxiao",
      "photoUrl": "",
      "userId": "05167076769245149404"
     },
     "user_tz": 240
    },
    "id": "62r9PZ4xzlFr",
    "outputId": "cfb82339-0ef7-45d0-8a1e-c1f121b7f1ba",
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Print the dimension of df_val\n",
    "pd.DataFrame([[df_val.shape[0], df_val.shape[1]]], columns=['# rows', '# columns'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 80
    },
    "executionInfo": {
     "elapsed": 35907,
     "status": "ok",
     "timestamp": 1601086969115,
     "user": {
      "displayName": "Huang Yuxiao",
      "photoUrl": "",
      "userId": "05167076769245149404"
     },
     "user_tz": 240
    },
    "id": "mBrwWXxGzlFs",
    "outputId": "428937e4-5535-44a8-8436-c4f3dc7ee432",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Print the dimension of df_test\n",
    "pd.DataFrame([[df_test.shape[0], df_test.shape[1]]], columns=['# rows', '# columns'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GXgfnUoczlFt",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Imputing missing values\n",
    "The code below shows how to use the mean of a numerical feature to impute its missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 35906,
     "status": "ok",
     "timestamp": 1601086969115,
     "user": {
      "displayName": "Huang Yuxiao",
      "photoUrl": "",
      "userId": "05167076769245149404"
     },
     "user_tz": 240
    },
    "id": "tcS8mYR0zlFu",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# If there are missing values\n",
    "if len(df_miss['var']) > 0:\n",
    "    # The SimpleImputer\n",
    "    si = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "\n",
    "    # Impute the variables with missing values in df_train, df_val and df_test \n",
    "    df_train[df_miss['var']] = si.fit_transform(df_train[df_miss['var']])\n",
    "    df_val[df_miss['var']] = si.transform(df_val[df_miss['var']])\n",
    "    df_test[df_miss['var']] = si.transform(df_test[df_miss['var']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HWcUkrUCzlFv",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Encoding the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ezQ07Z9dzlFv",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Combining the training, validation and test data\n",
    "The code below shows how to combine the training, validation and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 142
    },
    "executionInfo": {
     "elapsed": 35883,
     "status": "ok",
     "timestamp": 1601086969116,
     "user": {
      "displayName": "Huang Yuxiao",
      "photoUrl": "",
      "userId": "05167076769245149404"
     },
     "user_tz": 240
    },
    "id": "fYrsGD60zlFv",
    "outputId": "5f840959-e9bd-4589-f965-c23a978e14d2",
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Combine df_train, df_val and df_test\n",
    "df = pd.concat([df_train, df_val, df_test], sort=False)\n",
    "\n",
    "# Print the unique data type of variables in df\n",
    "pd.DataFrame(df.dtypes.unique(), columns=['dtype'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4qr55-jtzlFw",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Identifying categorical variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1rNrzzadzlFx",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The code below shows how to find categorical variables (whose data type is dtype) and their number of unique value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 35861,
     "status": "ok",
     "timestamp": 1601086969116,
     "user": {
      "displayName": "Huang Yuxiao",
      "photoUrl": "",
      "userId": "05167076769245149404"
     },
     "user_tz": 240
    },
    "id": "bguGxquQzlFx",
    "outputId": "3bdeda36-f5d3-40ef-d973-fcb9e752a54a",
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Call cat_var_checker on df\n",
    "# See the implementation in pmlm_utilities.ipynb\n",
    "df_cat = cat_var_checker(df)\n",
    "\n",
    "# Print the dataframe\n",
    "df_cat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hFantdOvzlFy",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Encoding categorical features\n",
    "The code below shows how to encode categorical features in the combined data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 253
    },
    "executionInfo": {
     "elapsed": 36415,
     "status": "ok",
     "timestamp": 1601086969693,
     "user": {
      "displayName": "Huang Yuxiao",
      "photoUrl": "",
      "userId": "05167076769245149404"
     },
     "user_tz": 240
    },
    "id": "VHiPUWGqzlFy",
    "outputId": "a5eecd9e-278e-4ab2-b11a-b34ba102bdaa",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# One-hot-encode the categorical features in the combined data\n",
    "df = pd.get_dummies(df, columns=np.setdiff1d(df_cat['var'], [target]))\n",
    "\n",
    "# Print the first 5 rows of df\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M4nnAv_YzlFz",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Separating the training, validation and test data\n",
    "The code below shows how to separate the training, validation and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 36414,
     "status": "ok",
     "timestamp": 1601086969693,
     "user": {
      "displayName": "Huang Yuxiao",
      "photoUrl": "",
      "userId": "05167076769245149404"
     },
     "user_tz": 240
    },
    "id": "53RGy5NRzlF0",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Separating the training data\n",
    "df_train = df.iloc[:df_train.shape[0], :]\n",
    "\n",
    "# Separating the validation data\n",
    "df_val = df.iloc[df_train.shape[0]:df_train.shape[0] + df_val.shape[0], :]\n",
    "\n",
    "# Separating the test data\n",
    "df_test = df.iloc[df_train.shape[0] + df_val.shape[0]:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 80
    },
    "executionInfo": {
     "elapsed": 36391,
     "status": "ok",
     "timestamp": 1601086969694,
     "user": {
      "displayName": "Huang Yuxiao",
      "photoUrl": "",
      "userId": "05167076769245149404"
     },
     "user_tz": 240
    },
    "id": "kz0qdOrlzlF1",
    "outputId": "a6049f62-def0-4d7b-f88a-1904ff722e60",
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Print the dimension of df_train\n",
    "pd.DataFrame([[df_train.shape[0], df_train.shape[1]]], columns=['# rows', '# columns'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 80
    },
    "executionInfo": {
     "elapsed": 36369,
     "status": "ok",
     "timestamp": 1601086969694,
     "user": {
      "displayName": "Huang Yuxiao",
      "photoUrl": "",
      "userId": "05167076769245149404"
     },
     "user_tz": 240
    },
    "id": "AOhCPkt3zlF2",
    "outputId": "d2fbe37b-f980-474f-98d2-e7ae865cd198",
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Print the dimension of df_val\n",
    "pd.DataFrame([[df_val.shape[0], df_val.shape[1]]], columns=['# rows', '# columns'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 80
    },
    "executionInfo": {
     "elapsed": 36347,
     "status": "ok",
     "timestamp": 1601086969695,
     "user": {
      "displayName": "Huang Yuxiao",
      "photoUrl": "",
      "userId": "05167076769245149404"
     },
     "user_tz": 240
    },
    "id": "Z1unjEYDzlF4",
    "outputId": "546143da-153e-428d-885e-699296ff5267",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Print the dimension of df_test\n",
    "pd.DataFrame([[df_test.shape[0], df_test.shape[1]]], columns=['# rows', '# columns'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Edju_Ur9zlF8",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Splitting the feature and target\n",
    "The code below shows how to split the feature and target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 36345,
     "status": "ok",
     "timestamp": 1601086969695,
     "user": {
      "displayName": "Huang Yuxiao",
      "photoUrl": "",
      "userId": "05167076769245149404"
     },
     "user_tz": 240
    },
    "id": "GM7JSraLzlF8",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Get the feature matrix\n",
    "X_train = df_train[np.setdiff1d(df_train.columns, [target])].values\n",
    "X_val = df_val[np.setdiff1d(df_val.columns, [target])].values\n",
    "X_test = df_test[np.setdiff1d(df_test.columns, [target])].values\n",
    "\n",
    "# Get the target vector\n",
    "y_train = df_train[target].values\n",
    "y_val = df_val[target].values\n",
    "y_test = df_test[target].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S7-Kc1AyzlF7",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Scaling the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r57KWJ8iNDpM",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Standardization\n",
    "The code below shows how to standardize the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 36344,
     "status": "ok",
     "timestamp": 1601086969695,
     "user": {
      "displayName": "Huang Yuxiao",
      "photoUrl": "",
      "userId": "05167076769245149404"
     },
     "user_tz": 240
    },
    "id": "giUXjP5SzlF7",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# The StandardScaler\n",
    "ss = StandardScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_nEHtF6hyJLc",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Standardizing the features\n",
    "The code below shows how to standardize the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 36343,
     "status": "ok",
     "timestamp": 1601086969696,
     "user": {
      "displayName": "Huang Yuxiao",
      "photoUrl": "",
      "userId": "05167076769245149404"
     },
     "user_tz": 240
    },
    "id": "vcCDFHDYyJLc",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Standardize the training data\n",
    "X_train = ss.fit_transform(X_train)\n",
    "\n",
    "# Standardize the validation data\n",
    "X_val = ss.transform(X_val)\n",
    "\n",
    "# Standardize the test data\n",
    "X_test = ss.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XaUxXPJeXY2k",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Standardizing the target\n",
    "The code below shows how to standardize the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 36342,
     "status": "ok",
     "timestamp": 1601086969696,
     "user": {
      "displayName": "Huang Yuxiao",
      "photoUrl": "",
      "userId": "05167076769245149404"
     },
     "user_tz": 240
    },
    "id": "fqy3Xe3XXY2k",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Standardize the training data\n",
    "y_train = ss.fit_transform(y_train.reshape(-1, 1)).reshape(-1)\n",
    "\n",
    "# Standardize the validation data\n",
    "y_val = ss.transform(y_val.reshape(-1, 1)).reshape(-1)\n",
    "\n",
    "# Standardize the test data\n",
    "y_test = ss.transform(y_test.reshape(-1, 1)).reshape(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Of56ObPGe31x",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jYCH8GB-e31z",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Creating the dictionary of the models\n",
    "- In the dictionary:\n",
    "    - the key is the acronym of the model\n",
    "    - the value is the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 36341,
     "status": "ok",
     "timestamp": 1601086969697,
     "user": {
      "displayName": "Huang Yuxiao",
      "photoUrl": "",
      "userId": "05167076769245149404"
     },
     "user_tz": 240
    },
    "id": "T5h3IQo9e31z",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDRegressor\n",
    "\n",
    "models = {'sgd': SGDRegressor(random_state=random_seed)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ju9FdEVce310",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Creating the dictionary of the pipelines\n",
    "In the dictionary:\n",
    "- the key is the acronym of the model\n",
    "- the value is the pipeline, which, for now, only includes the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 36340,
     "status": "ok",
     "timestamp": 1601086969697,
     "user": {
      "displayName": "Huang Yuxiao",
      "photoUrl": "",
      "userId": "05167076769245149404"
     },
     "user_tz": 240
    },
    "id": "zc-L-914e310",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipes = {}\n",
    "\n",
    "for acronym, model in models.items():\n",
    "    pipes[acronym] = Pipeline([('model', model)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BgkFbGGKe311",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Getting the predefined split cross-validator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 36340,
     "status": "ok",
     "timestamp": 1601086969698,
     "user": {
      "displayName": "Huang Yuxiao",
      "photoUrl": "",
      "userId": "05167076769245149404"
     },
     "user_tz": 240
    },
    "id": "6FAACb8ke311",
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get the:\n",
    "# feature matrix and target velctor in the combined training and validation data\n",
    "# target vector in the combined training and validation data\n",
    "# PredefinedSplit\n",
    "# See the implementation in pmlm_utilities.ipynb\n",
    "X_train_val, y_train_val, ps = get_train_val_ps(X_train, y_train, X_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I3rZoMqZe312",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E08xqUQve313",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Creating the dictionary of the parameter grids\n",
    "- In the dictionary:\n",
    "    - the key is the acronym of the model\n",
    "    - the value is the parameter grid of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 36338,
     "status": "ok",
     "timestamp": 1601086969698,
     "user": {
      "displayName": "Huang Yuxiao",
      "photoUrl": "",
      "userId": "05167076769245149404"
     },
     "user_tz": 240
    },
    "id": "p3OWujL3e313",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "param_grids = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9EyKhepjmV6P",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### The parameter grid for SGDRegressor\n",
    "- The hyperparameters we want to fine-tune are:\n",
    "    - eta0\n",
    "    - alpha\n",
    "- See details of the meaning of the hyperparametes in [sklearn.linear_model.SGDRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDRegressor.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 36337,
     "status": "ok",
     "timestamp": 1601086969698,
     "user": {
      "displayName": "Huang Yuxiao",
      "photoUrl": "",
      "userId": "05167076769245149404"
     },
     "user_tz": 240
    },
    "id": "i2Mv1rffnJpN",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# The parameter grid of eta\n",
    "eta_grid = [0.001, 0.01]\n",
    "\n",
    "# The parameter grid of alpha\n",
    "alpha_grid = [0.01, 0.1]\n",
    "\n",
    "# Update param_grids\n",
    "param_grids['sgd'] = [{'model__eta0': eta_grid,\n",
    "                       'model__alpha': alpha_grid}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LRabeGs4WaHX",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Creating the directory for the cv results produced by GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 36337,
     "status": "ok",
     "timestamp": 1601086969699,
     "user": {
      "displayName": "Huang Yuxiao",
      "photoUrl": "",
      "userId": "05167076769245149404"
     },
     "user_tz": 240
    },
    "id": "uO7Yd15JWaHY",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Make directory\n",
    "directory = os.path.dirname(abspath_curr + 'result/cv_results/GridSearchCV/')\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sVIuo08Ze31-",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Tuning the hyperparameters\n",
    "The code below shows how to fine-tune the hyperparameters of SGDRegressor and LinearRegression_MBGD using sklearn GridSearchCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 80
    },
    "executionInfo": {
     "elapsed": 38117,
     "status": "ok",
     "timestamp": 1601086971503,
     "user": {
      "displayName": "Huang Yuxiao",
      "photoUrl": "",
      "userId": "05167076769245149404"
     },
     "user_tz": 240
    },
    "id": "DwA4WZlFe31-",
    "outputId": "e676554c-9efb-43c4-a0cb-80a3bf57e596",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# The list of [best_score_, best_params_, best_estimator_] obtained by GridSearchCV\n",
    "best_score_params_estimator_gs = []\n",
    "\n",
    "# For each model\n",
    "for acronym in pipes.keys():\n",
    "    # GridSearchCV\n",
    "    gs = GridSearchCV(estimator=pipes[acronym],\n",
    "                      param_grid=param_grids[acronym],\n",
    "                      scoring='neg_mean_squared_error',\n",
    "                      n_jobs=2,\n",
    "                      cv=ps,\n",
    "                      return_train_score=True)\n",
    "        \n",
    "    # Fit the pipeline\n",
    "    gs = gs.fit(X_train_val, y_train_val)\n",
    "    \n",
    "    # Update best_score_params_estimator_gs\n",
    "    best_score_params_estimator_gs.append([gs.best_score_, gs.best_params_, gs.best_estimator_])\n",
    "    \n",
    "    # Sort cv_results in ascending order of 'rank_test_score' and 'std_test_score'\n",
    "    cv_results = pd.DataFrame.from_dict(gs.cv_results_).sort_values(by=['rank_test_score', 'std_test_score'])\n",
    "    \n",
    "    # Get the important columns in cv_results\n",
    "    important_columns = ['rank_test_score',\n",
    "                         'mean_test_score', \n",
    "                         'std_test_score', \n",
    "                         'mean_train_score', \n",
    "                         'std_train_score',\n",
    "                         'mean_fit_time', \n",
    "                         'std_fit_time',                        \n",
    "                         'mean_score_time', \n",
    "                         'std_score_time']\n",
    "    \n",
    "    # Move the important columns ahead\n",
    "    cv_results = cv_results[important_columns + sorted(list(set(cv_results.columns) - set(important_columns)))]\n",
    "\n",
    "    # Write cv_results file\n",
    "    cv_results.to_csv(path_or_buf=abspath_curr + 'result/cv_results/GridSearchCV/' + acronym + '.csv', index=False)\n",
    "\n",
    "# Sort best_score_params_estimator_gs in descending order of the best_score_\n",
    "best_score_params_estimator_gs = sorted(best_score_params_estimator_gs, key=lambda x : x[0], reverse=True)\n",
    "\n",
    "# Print best_score_params_estimator_gs\n",
    "pd.DataFrame(best_score_params_estimator_gs, columns=['best_score', 'best_param', 'best_estimator'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kOF6id8le32I",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Model Selection\n",
    "Here we will select best_estimator_gs as the best model. Later we will use this best model to generate the submission file for this kaggle competition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 38115,
     "status": "ok",
     "timestamp": 1601086971503,
     "user": {
      "displayName": "Huang Yuxiao",
      "photoUrl": "",
      "userId": "05167076769245149404"
     },
     "user_tz": 240
    },
    "id": "IjbLGmXPe32J",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Get the best_score, best_params and best_estimator obtained by GridSearchCV\n",
    "best_score_gs, best_params_gs, best_estimator_gs = best_score_params_estimator_gs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fiEBpqc_e32K",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Generating the Submission File\n",
    "Use the best model selected earlier to generate the submission file for this kaggle competition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Aw5WYTRGz65s",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Creating the directory for the submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 38115,
     "status": "ok",
     "timestamp": 1601086971504,
     "user": {
      "displayName": "Huang Yuxiao",
      "photoUrl": "",
      "userId": "05167076769245149404"
     },
     "user_tz": 240
    },
    "id": "z0oLcggN0C9W",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Make directory\n",
    "directory = os.path.dirname(abspath_curr + 'result/submission/')\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y-Qf_8VM0Tt9",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Generating the submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 38114,
     "status": "ok",
     "timestamp": 1601086971504,
     "user": {
      "displayName": "Huang Yuxiao",
      "photoUrl": "",
      "userId": "05167076769245149404"
     },
     "user_tz": 240
    },
    "id": "mVdD3N0re32L",
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get the prediction on the testing data using the best model\n",
    "y_test_pred = best_estimator_gs.predict(X_test)\n",
    "\n",
    "# Get the dataframe of y_test_pred, which has the same shape as df_train\n",
    "df_y_test_pred = pd.DataFrame(np.tile(y_test_pred.reshape(-1, 1), df_train.shape[1]),\n",
    "                              columns=df_train.columns)\n",
    "\n",
    "# Transform df_y_test_pred back to the original scale\n",
    "df_y_test_pred = pd.DataFrame(ss.inverse_transform(df_y_test_pred),\n",
    "                              columns=df_train.columns)\n",
    "\n",
    "# Get the submission dataframe\n",
    "df_submit = pd.DataFrame(np.hstack((df_raw_test[['Id']], df_y_test_pred[[target]])),\n",
    "                         columns=['Id', target]).astype({'Id':int, target:float})                                                                                       \n",
    "\n",
    "# Generate the submission file\n",
    "df_submit.to_csv(abspath_curr + 'result/submission/submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "case_study.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
