{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0QJDNuifaIwP",
    "pycharm": {
     "name": "#%% md\n"
    },
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Overview\" data-toc-modified-id=\"Overview-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Overview</a></span></li><li><span><a href=\"#Notebook-Configuration\" data-toc-modified-id=\"Notebook-Configuration-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Notebook Configuration</a></span><ul class=\"toc-item\"><li><span><a href=\"#Google-drive\" data-toc-modified-id=\"Google-drive-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Google drive</a></span></li><li><span><a href=\"#Warning\" data-toc-modified-id=\"Warning-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Warning</a></span></li><li><span><a href=\"#Matplotlib\" data-toc-modified-id=\"Matplotlib-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Matplotlib</a></span></li><li><span><a href=\"#TensorFlow\" data-toc-modified-id=\"TensorFlow-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>TensorFlow</a></span></li><li><span><a href=\"#Random-seed\" data-toc-modified-id=\"Random-seed-2.5\"><span class=\"toc-item-num\">2.5&nbsp;&nbsp;</span>Random seed</a></span></li></ul></li><li><span><a href=\"#Data-Preprocessing\" data-toc-modified-id=\"Data-Preprocessing-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Data Preprocessing</a></span></li><li><span><a href=\"#Hyperparameter-Tuning\" data-toc-modified-id=\"Hyperparameter-Tuning-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Hyperparameter Tuning</a></span></li><li><span><a href=\"#Model-Selection\" data-toc-modified-id=\"Model-Selection-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Model Selection</a></span></li><li><span><a href=\"#Generating-the-Submission-File\" data-toc-modified-id=\"Generating-the-Submission-File-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Generating the Submission File</a></span><ul class=\"toc-item\"><li><span><a href=\"#Creating-the-directory-for-the-submission-file\" data-toc-modified-id=\"Creating-the-directory-for-the-submission-file-6.1\"><span class=\"toc-item-num\">6.1&nbsp;&nbsp;</span>Creating the directory for the submission file</a></span></li><li><span><a href=\"#Generating-the-submission-file\" data-toc-modified-id=\"Generating-the-submission-file-6.2\"><span class=\"toc-item-num\">6.2&nbsp;&nbsp;</span>Generating the submission file</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "42yc1zUrzlEh",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<b>\n",
    "<p>\n",
    "<center>\n",
    "<font size=\"5\">\n",
    "Popular Machine Learning Methods: Idea, Practice and Math\n",
    "</font>\n",
    "</center>\n",
    "</p>\n",
    "\n",
    "<p>\n",
    "<center>\n",
    "<font size=\"4\">\n",
    "Part 2, Chapter 2, Section 4: Shallow Neural Networks\n",
    "</font>\n",
    "</center>\n",
    "</p>\n",
    "    \n",
    "<p>\n",
    "<center>\n",
    "<font size=\"4\">\n",
    "Homework 2\n",
    "</font>\n",
    "</center>\n",
    "</p>\n",
    "\n",
    "<p>\n",
    "<center>\n",
    "<font size=\"3\">\n",
    "Data Science, Columbian College of Arts & Sciences, George Washington University\n",
    "</font>\n",
    "</center>\n",
    "</p>\n",
    "\n",
    "<p>\n",
    "<center>\n",
    "<font size=\"3\">\n",
    "Yuxiao Huang\n",
    "</font>\n",
    "</center>\n",
    "</p>\n",
    "</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rT2SKHw2zlEi",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "asZWLrJKzlEj",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "- This notebook includes homework 2 for Shallow Neural Networks (Part 2, Chapter 2, Section 4).\n",
    "- See the accompanied slides in our [github repository](https://github.com/yuxiaohuang/teaching/tree/master/gwu/machine_learning_I/fall_2022/slides/p2_shallow_learning/p2_c2_supervised_learning/p2_c2_s4_shallow_neural_networks).\n",
    "- Here we will work on kaggle competation [Santander Customer Transaction Prediction].(https://www.kaggle.com/c/santander-customer-transaction-prediction/overview)\n",
    "- The goal of this homework is tweaking the pipeline (including data preprocessing, hyperparameter tuning and model selection) implemented in [/p2 c2 s4 shallow neural_networks/case_study](https://github.com/yuxiaohuang/teaching/blob/master/gwu/machine_learning_I/fall_2022/code/p2_shallow_learning/p2_c2_supervised_learning/p2_c2_s4_shallow_neural_networks/case_study/case_study.ipynb) to make it work for the new kaggle competation mentioned above.\n",
    "- Complete the missing parts indicated by # Implement me.\n",
    "- Particularly, the code should\n",
    "    - be bug-free (note that the output produced by your solution may not necessarily be the same as the provided output, due to version issues)\n",
    "    - be commented\n",
    "- **The baseline for this assignment is 0.670522. As per the grading rubrics (section 15 of the syllabus), if the validation score of your best model is lower than or the same as the baseline, you will only receive 80% of the full mark. See more details in the grading rubrics.**\n",
    "- Submit an ipynb file named homework_2.ipynb to [blackboard](https://blackboard.gwu.edu) folder /Assignments/Homework_2/."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WJ-IbZqAgILJ",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Notebook Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H3yB94KtgMHu",
    "jp-MarkdownHeadingCollapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "## Google drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "executionInfo": {
     "elapsed": 19370,
     "status": "ok",
     "timestamp": 1602476890219,
     "user": {
      "displayName": "Huang Yuxiao",
      "photoUrl": "",
      "userId": "05167076769245149404"
     },
     "user_tz": 240
    },
    "id": "jWmYBTOwgNs-",
    "outputId": "e3a52cd0-08fb-443f-85c6-8a233dca1a12",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "import sys\n",
    "\n",
    "# Mount Google Drive\n",
    "# drive.mount('/content/drive')\n",
    "\n",
    "# Get the absolute path of the current folder\n",
    "abspath_curr = ''\n",
    "\n",
    "# Get the absolute path of the shallow utilities folder\n",
    "abspath_util_shallow = ''\n",
    "\n",
    "# Get the absolute path of the shallow models folder\n",
    "abspath_model_shallow = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bYZhU1Wqgmqx",
    "jp-MarkdownHeadingCollapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "## Warning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "MUl4k83e4ANR",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "# Ignore warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6WMODpPfgn2U",
    "jp-MarkdownHeadingCollapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "## Matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "DBRVH9SB4ANb",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "# Set matplotlib sizes\n",
    "plt.rc('font', size=20)\n",
    "plt.rc('axes', titlesize=20)\n",
    "plt.rc('axes', labelsize=20)\n",
    "plt.rc('xtick', labelsize=20)\n",
    "plt.rc('ytick', labelsize=20)\n",
    "plt.rc('legend', fontsize=20)\n",
    "plt.rc('figure', titlesize=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n-wNDk5nZhhO",
    "jp-MarkdownHeadingCollapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "## TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "LjG43tEnZkfE",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# The magic below allows us to use tensorflow version 2.x\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='1'\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH']='true'\n",
    "# %tensorflow_version 2.x\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "40FN3UNfO2Z7",
    "jp-MarkdownHeadingCollapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "## Random seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "uSADk0hJP71d",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# The random seed\n",
    "random_seed = 42\n",
    "\n",
    "# Set random seed in tensorflow\n",
    "tf.random.set_seed(random_seed)\n",
    "\n",
    "# Set random seed in numpy\n",
    "import numpy as np\n",
    "np.random.seed(random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yAwfz8iYzlFC",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Import utilities notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "executionInfo": {
     "elapsed": 23564,
     "status": "ok",
     "timestamp": 1602476894453,
     "user": {
      "displayName": "Huang Yuxiao",
      "photoUrl": "",
      "userId": "05167076769245149404"
     },
     "user_tz": 240
    },
    "id": "D-Mwc6MczlFD",
    "outputId": "524cf199-e9a1-4f47-99c5-b827bf16a011",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Change working directory to the absolute path of the shallow utilities folder\n",
    "# %cd $abspath_util_shallow\n",
    "\n",
    "# Import the shallow utitilities\n",
    "%run pmlm_utilities_shallow.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "GMm53nLtlx_G",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_raw_train = pd.read_csv(abspath_curr + 'data/train.csv', header=0)\n",
    "df_train = df_raw_train.copy(deep=True)\n",
    "\n",
    "df_raw_test = pd.read_csv(abspath_curr + 'data/test.csv', header=0)\n",
    "df_test = df_raw_test.copy(deep=True)\n",
    "\n",
    "target = 'target'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Instances</th>\n",
       "      <th>Features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Training</th>\n",
       "      <td>200000</td>\n",
       "      <td>202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Testing</th>\n",
       "      <td>200000</td>\n",
       "      <td>201</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Instances  Features\n",
       "Training     200000       202\n",
       "Testing      200000       201"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the dimension of df_train\n",
    "pd.DataFrame({'Training':{'Instances':df_train.shape[0], 'Features':df_train.shape[1]},\n",
    "              'Testing':{'Instances':df_test.shape[0], 'Features':df_test.shape[1]}}).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Glimpse of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_code</th>\n",
       "      <th>target</th>\n",
       "      <th>var_0</th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>...</th>\n",
       "      <th>var_190</th>\n",
       "      <th>var_191</th>\n",
       "      <th>var_192</th>\n",
       "      <th>var_193</th>\n",
       "      <th>var_194</th>\n",
       "      <th>var_195</th>\n",
       "      <th>var_196</th>\n",
       "      <th>var_197</th>\n",
       "      <th>var_198</th>\n",
       "      <th>var_199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.9255</td>\n",
       "      <td>-6.7863</td>\n",
       "      <td>11.9081</td>\n",
       "      <td>5.0930</td>\n",
       "      <td>11.4607</td>\n",
       "      <td>-9.2834</td>\n",
       "      <td>5.1187</td>\n",
       "      <td>18.6266</td>\n",
       "      <td>...</td>\n",
       "      <td>4.4354</td>\n",
       "      <td>3.9642</td>\n",
       "      <td>3.1364</td>\n",
       "      <td>1.6910</td>\n",
       "      <td>18.5227</td>\n",
       "      <td>-2.3978</td>\n",
       "      <td>7.8784</td>\n",
       "      <td>8.5635</td>\n",
       "      <td>12.7803</td>\n",
       "      <td>-1.0914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_1</td>\n",
       "      <td>0</td>\n",
       "      <td>11.5006</td>\n",
       "      <td>-4.1473</td>\n",
       "      <td>13.8588</td>\n",
       "      <td>5.3890</td>\n",
       "      <td>12.3622</td>\n",
       "      <td>7.0433</td>\n",
       "      <td>5.6208</td>\n",
       "      <td>16.5338</td>\n",
       "      <td>...</td>\n",
       "      <td>7.6421</td>\n",
       "      <td>7.7214</td>\n",
       "      <td>2.5837</td>\n",
       "      <td>10.9516</td>\n",
       "      <td>15.4305</td>\n",
       "      <td>2.0339</td>\n",
       "      <td>8.1267</td>\n",
       "      <td>8.7889</td>\n",
       "      <td>18.3560</td>\n",
       "      <td>1.9518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_2</td>\n",
       "      <td>0</td>\n",
       "      <td>8.6093</td>\n",
       "      <td>-2.7457</td>\n",
       "      <td>12.0805</td>\n",
       "      <td>7.8928</td>\n",
       "      <td>10.5825</td>\n",
       "      <td>-9.0837</td>\n",
       "      <td>6.9427</td>\n",
       "      <td>14.6155</td>\n",
       "      <td>...</td>\n",
       "      <td>2.9057</td>\n",
       "      <td>9.7905</td>\n",
       "      <td>1.6704</td>\n",
       "      <td>1.6858</td>\n",
       "      <td>21.6042</td>\n",
       "      <td>3.1417</td>\n",
       "      <td>-6.5213</td>\n",
       "      <td>8.2675</td>\n",
       "      <td>14.7222</td>\n",
       "      <td>0.3965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_3</td>\n",
       "      <td>0</td>\n",
       "      <td>11.0604</td>\n",
       "      <td>-2.1518</td>\n",
       "      <td>8.9522</td>\n",
       "      <td>7.1957</td>\n",
       "      <td>12.5846</td>\n",
       "      <td>-1.8361</td>\n",
       "      <td>5.8428</td>\n",
       "      <td>14.9250</td>\n",
       "      <td>...</td>\n",
       "      <td>4.4666</td>\n",
       "      <td>4.7433</td>\n",
       "      <td>0.7178</td>\n",
       "      <td>1.4214</td>\n",
       "      <td>23.0347</td>\n",
       "      <td>-1.2706</td>\n",
       "      <td>-2.9275</td>\n",
       "      <td>10.2922</td>\n",
       "      <td>17.9697</td>\n",
       "      <td>-8.9996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_4</td>\n",
       "      <td>0</td>\n",
       "      <td>9.8369</td>\n",
       "      <td>-1.4834</td>\n",
       "      <td>12.8746</td>\n",
       "      <td>6.6375</td>\n",
       "      <td>12.2772</td>\n",
       "      <td>2.4486</td>\n",
       "      <td>5.9405</td>\n",
       "      <td>19.2514</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.4905</td>\n",
       "      <td>9.5214</td>\n",
       "      <td>-0.1508</td>\n",
       "      <td>9.1942</td>\n",
       "      <td>13.2876</td>\n",
       "      <td>-1.5121</td>\n",
       "      <td>3.9267</td>\n",
       "      <td>9.5031</td>\n",
       "      <td>17.9974</td>\n",
       "      <td>-8.8104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 202 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID_code  target    var_0   var_1    var_2   var_3    var_4   var_5   var_6  \\\n",
       "0  train_0       0   8.9255 -6.7863  11.9081  5.0930  11.4607 -9.2834  5.1187   \n",
       "1  train_1       0  11.5006 -4.1473  13.8588  5.3890  12.3622  7.0433  5.6208   \n",
       "2  train_2       0   8.6093 -2.7457  12.0805  7.8928  10.5825 -9.0837  6.9427   \n",
       "3  train_3       0  11.0604 -2.1518   8.9522  7.1957  12.5846 -1.8361  5.8428   \n",
       "4  train_4       0   9.8369 -1.4834  12.8746  6.6375  12.2772  2.4486  5.9405   \n",
       "\n",
       "     var_7  ...  var_190  var_191  var_192  var_193  var_194  var_195  \\\n",
       "0  18.6266  ...   4.4354   3.9642   3.1364   1.6910  18.5227  -2.3978   \n",
       "1  16.5338  ...   7.6421   7.7214   2.5837  10.9516  15.4305   2.0339   \n",
       "2  14.6155  ...   2.9057   9.7905   1.6704   1.6858  21.6042   3.1417   \n",
       "3  14.9250  ...   4.4666   4.7433   0.7178   1.4214  23.0347  -1.2706   \n",
       "4  19.2514  ...  -1.4905   9.5214  -0.1508   9.1942  13.2876  -1.5121   \n",
       "\n",
       "   var_196  var_197  var_198  var_199  \n",
       "0   7.8784   8.5635  12.7803  -1.0914  \n",
       "1   8.1267   8.7889  18.3560   1.9518  \n",
       "2  -6.5213   8.2675  14.7222   0.3965  \n",
       "3  -2.9275  10.2922  17.9697  -8.9996  \n",
       "4   3.9267   9.5031  17.9974  -8.8104  \n",
       "\n",
       "[5 rows x 202 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Splitting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Instances</th>\n",
       "      <th>Features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Training</th>\n",
       "      <td>128000</td>\n",
       "      <td>202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Testing</th>\n",
       "      <td>200000</td>\n",
       "      <td>201</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Instances  Features\n",
       "Training     128000       202\n",
       "Testing      200000       201"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Divide the training data into training (80%) and validation (20%)\n",
    "df_train, df_val = train_test_split(df_train, train_size=0.8, random_state=random_seed)\n",
    "\n",
    "# Reset the index\n",
    "df_train, df_val = df_train.reset_index(drop=True), df_val.reset_index(drop=True)\n",
    "\n",
    "# Print the dimension of df_train\n",
    "pd.DataFrame({'Training':{'Instances':df_train.shape[0], 'Features':df_train.shape[1]},\n",
    "              'Testing':{'Instances':df_test.shape[0], 'Features':df_test.shape[1]}}).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Handling uncommon features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call common_var_checker\n",
    "# See the implementation in pmlm_utilities.ipynb\n",
    "df_common_var = common_var_checker(df_train, df_val, df_test, target)\n",
    "\n",
    "# Print df_common_var\n",
    "# df_common_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "uncommon_feature_train_not_val_test = np.setdiff1d(df_train.columns, df_common_var['common var'])\n",
    "uncommon_feature_val_not_train_test = np.setdiff1d(df_val.columns, df_common_var['common var'])\n",
    "uncommon_feature_test_not_train_val = np.setdiff1d(df_test.columns, df_common_var['common var'])\n",
    "\n",
    "# Print the uncommon features\n",
    "if len(uncommon_feature_train_not_val_test) > 0:\n",
    "    print(f'Training:\\n{pd.DataFrame(uncommon_feature_train_not_val_test, columns=[\"uncommon feature\"])}')\n",
    "    df_train = df_train.drop(columns=uncommon_feature_train_not_val_test)\n",
    "\n",
    "if len(uncommon_feature_val_not_train_test) > 0:\n",
    "    print(f'Validation:\\n\\n{pd.DataFrame(uncommon_feature_val_not_train_test, columns=[\"uncommon feature\"])}')\n",
    "    df_val = df_val.drop(columns=uncommon_feature_val_not_train_test)\n",
    "    \n",
    "if len(uncommon_feature_test_not_train_val) > 0:\n",
    "    print(f'Testing:\\n\\n{pd.DataFrame(uncommon_feature_test_not_train_val, columns=[\"uncommon feature\"])}')\n",
    "    df_test = df_test.drop(columns=uncommon_feature_test_not_train_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Handling Identifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve the identifier columns and have them removed from all subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df_train, df_val, df_test], sort=False)\n",
    "df_id = id_checker(df)\n",
    "\n",
    "# Remove identifiers from df_train\n",
    "df_train.drop(columns=np.intersect1d(df_id.columns, df_train.columns), inplace=True)\n",
    "# Remove identifiers from df_val\n",
    "df_val.drop(columns=np.intersect1d(df_id.columns, df_val.columns), inplace=True)\n",
    "# Remove identifiers from df_test\n",
    "df_test.drop(columns=np.intersect1d(df_id.columns, df_test.columns), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Note: At this stage only the subsets have the up to date copy, not the combined df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## DateTime Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target    int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.dtypes[df_train.dtypes != 'float64']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### This step is ignored as it appears that there exist no date time attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Identify and impute the missing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### It is wise to combine the subsets here once again as only the subsets are up to date after the identifier removal step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var</th>\n",
       "      <th>proportion</th>\n",
       "      <th>dtype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>target</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      var  proportion    dtype\n",
       "0  target    0.555556  float64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([df_train, df_val, df_test], sort=False)\n",
    "df_nan = nan_checker(df)\n",
    "df_nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Since the data in the df is not shuffled, the subsets should remain in their respective position that we can access them with the aid of subset's size. Perhaps we can use the train set to estimate the statistical parameters of the distribution, and use it to impute the missing values on the other sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Instances</th>\n",
       "      <th>Features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Training</th>\n",
       "      <td>128000</td>\n",
       "      <td>201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Testing</th>\n",
       "      <td>200000</td>\n",
       "      <td>201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Validation</th>\n",
       "      <td>32000</td>\n",
       "      <td>201</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Instances  Features\n",
       "Training       128000       201\n",
       "Testing        200000       201\n",
       "Validation      32000       201"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Segregating the data again\n",
    "df_train = df.iloc[:df_train.shape[0], :]\n",
    "df_val = df.iloc[df_train.shape[0]:df_train.shape[0] + df_val.shape[0], :]\n",
    "df_test = df.iloc[df_train.shape[0] + df_val.shape[0]:, :]\n",
    "\n",
    "# Print the dimension of df_train\n",
    "pd.DataFrame({'Training':{'Instances':df_train.shape[0], 'Features':df_train.shape[1]},\n",
    "              'Testing':{'Instances':df_test.shape[0], 'Features':df_test.shape[1]},\n",
    "              'Validation':{'Instances':df_val.shape[0], 'Features':df_val.shape[1]}}).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Define method to impute the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputation_method = 'SimpleImputer'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### One way of imputing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var</th>\n",
       "      <th>proportion</th>\n",
       "      <th>dtype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>target</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      var  proportion    dtype\n",
       "0  target    0.555556  float64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "if imputation_method == 'SimpleImputer':\n",
    "    # If there are missing values\n",
    "    if len(df_nan['var']) > 0:\n",
    "        # The SimpleImputer\n",
    "        si = SimpleImputer(missing_values=np.nan, strategy='most_frequent')\n",
    "\n",
    "        # Impute the variables with missing values in df_train, df_val and df_test \n",
    "        df_train[df_nan['var']] = si.fit_transform(df_train[df_nan['var']])\n",
    "        df_val[df_nan['var']] = si.transform(df_val[df_nan['var']])\n",
    "        df_test[df_nan['var']] = si.transform(df_test[df_nan['var']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Encoding the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], dtype: object)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes[df.dtypes != 'float64']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var</th>\n",
       "      <th>nunique</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [var, nunique]\n",
       "Index: []"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_var_checker(pd.concat([df_train, df_val, df_test], sort=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         0.0\n",
       "1         0.0\n",
       "2         0.0\n",
       "3         0.0\n",
       "4         0.0\n",
       "         ... \n",
       "127995    0.0\n",
       "127996    0.0\n",
       "127997    1.0\n",
       "127998    0.0\n",
       "127999    0.0\n",
       "Name: target, Length: 128000, dtype: float64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Since there are no categorical variables, I wish to ignore this step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Of56ObPGe31x",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2ICnjl3Olx_I",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Implement me"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kOF6id8le32I",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c2O8-Fv9lx_J",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Implement me"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fiEBpqc_e32K",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Generating the Submission File\n",
    "Use the best model selected earlier to generate the submission file for this kaggle competition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Aw5WYTRGz65s",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Creating the directory for the submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z0oLcggN0C9W",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Make directory\n",
    "directory = os.path.dirname(abspath_curr + '/result/submission/')\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y-Qf_8VM0Tt9",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Generating the submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mVdD3N0re32L",
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get the prediction on the test data using the best model\n",
    "y_test_pred = best_estimator_gs.predict(X_test)\n",
    "\n",
    "# Transform y_test_pred back to the original class\n",
    "y_test_pred = le.inverse_transform(y_test_pred)\n",
    "\n",
    "# Get the submission dataframe\n",
    "df_submit = pd.DataFrame(np.hstack((df_raw_test[['ID_code']], y_test_pred.reshape(-1, 1))),\n",
    "                         columns=['ID_code', target])                                                                                     \n",
    "\n",
    "# Generate the submission file\n",
    "df_submit.to_csv(abspath_curr + '/result/submission/submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Homework_2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
